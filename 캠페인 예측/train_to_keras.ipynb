{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "from sklearn import preprocessing\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./output/preprocess_object.pickle','rb') as f:\n",
    "    preprocess_object = pickle.load(f)\n",
    "\n",
    "dataset = pd.read_csv('./output/train_dataset.csv',delimiter=',',encoding='utf-8',low_memory=False)\n",
    "\n",
    "number_df = dataset.select_dtypes(include=['int64','float64'])\n",
    "#스케일러를 통한 전체 자료 분포 평균0, 분산1로 변환(오버플로우, 언더플로우 방지, 독립변수 공분산 행렬 조건수 감소) \n",
    "#--> 안정성 및 수렴속도 향상\n",
    "scaler = preprocess_object.pop('scaler')\n",
    "\n",
    "scaler_arr = scaler.transform(number_df)\n",
    "train_data = pd.DataFrame(scaler_arr, columns=number_df.columns)\n",
    "\n",
    "categorical = list(dataset.select_dtypes(include=['object']).columns)\n",
    "oh_encoder ={}\n",
    "\n",
    "for cat in categorical:\n",
    "    oh_encoder = preprocess_object[cat]\n",
    "    le = oh_encoder['LabelEncoder']\n",
    "    ohe = oh_encoder['OneHotEncoder']\n",
    "    cat_le_arr =le.transform(dataset[cat])\n",
    "    cat_ohe_arr = ohe.transform(cat_le_arr.reshape(-1,1)).toarray()\n",
    "    oh_df = pd.DataFrame(cat_ohe_arr, columns=[cat+'_'+le.inverse_transform([int(i)])[0] for i in range(cat_ohe_arr.shape[1])])\n",
    "    train_data=pd.concat([train_data, oh_df], axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        0.0\n",
      "1        0.0\n",
      "2        0.0\n",
      "3        1.0\n",
      "4        0.0\n",
      "5        1.0\n",
      "6        1.0\n",
      "7        1.0\n",
      "8        0.0\n",
      "9        0.0\n",
      "10       0.0\n",
      "11       0.0\n",
      "12       0.0\n",
      "13       0.0\n",
      "14       1.0\n",
      "15       1.0\n",
      "16       1.0\n",
      "17       1.0\n",
      "18       0.0\n",
      "19       1.0\n",
      "20       0.0\n",
      "21       0.0\n",
      "22       1.0\n",
      "23       1.0\n",
      "24       1.0\n",
      "25       0.0\n",
      "26       0.0\n",
      "27       0.0\n",
      "28       0.0\n",
      "29       1.0\n",
      "        ... \n",
      "25618    1.0\n",
      "25619    1.0\n",
      "25620    0.0\n",
      "25621    0.0\n",
      "25622    1.0\n",
      "25623    1.0\n",
      "25624    0.0\n",
      "25625    0.0\n",
      "25626    0.0\n",
      "25627    1.0\n",
      "25628    0.0\n",
      "25629    1.0\n",
      "25630    1.0\n",
      "25631    0.0\n",
      "25632    0.0\n",
      "25633    0.0\n",
      "25634    0.0\n",
      "25635    0.0\n",
      "25636    0.0\n",
      "25637    0.0\n",
      "25638    0.0\n",
      "25639    0.0\n",
      "25640    0.0\n",
      "25641    0.0\n",
      "25642    0.0\n",
      "25643    0.0\n",
      "25644    0.0\n",
      "25645    0.0\n",
      "25646    1.0\n",
      "25647    0.0\n",
      "Name: resp_N, Length: 25648, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(train_data['resp_N'])\n",
    "train_label = pd.DataFrame()\n",
    "train_label['resp_N'] = train_data['resp_N']\n",
    "train_label['resp_Y'] = train_data['resp_Y']\n",
    "\n",
    "del train_data['resp_N']\n",
    "del train_data['resp_Y']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(train_data.shape[1],input_dim=train_data.shape[1], activation='relu'))\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dense(100,activation='relu'))\n",
    "model.add(Dense(100,activation='relu'))\n",
    "model.add(Dense(2, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "25648/25648 [==============================] - 5s 189us/step - loss: 0.5696 - acc: 0.7079\n",
      "Epoch 2/10\n",
      "25648/25648 [==============================] - 2s 75us/step - loss: 0.5447 - acc: 0.7239\n",
      "Epoch 3/10\n",
      "25648/25648 [==============================] - 2s 76us/step - loss: 0.5299 - acc: 0.7334\n",
      "Epoch 4/10\n",
      "25648/25648 [==============================] - 2s 76us/step - loss: 0.5138 - acc: 0.7430\n",
      "Epoch 5/10\n",
      "25648/25648 [==============================] - 2s 76us/step - loss: 0.4950 - acc: 0.7568\n",
      "Epoch 6/10\n",
      "25648/25648 [==============================] - 2s 76us/step - loss: 0.4745 - acc: 0.7660\n",
      "Epoch 7/10\n",
      "25648/25648 [==============================] - 2s 77us/step - loss: 0.4487 - acc: 0.7815\n",
      "Epoch 8/10\n",
      "25648/25648 [==============================] - 2s 77us/step - loss: 0.4216 - acc: 0.7967\n",
      "Epoch 9/10\n",
      "25648/25648 [==============================] - 2s 77us/step - loss: 0.3954 - acc: 0.8104\n",
      "Epoch 10/10\n",
      "25648/25648 [==============================] - 2s 77us/step - loss: 0.3675 - acc: 0.8276\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a5bd3f4940>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_data,train_label,epochs=10, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25648/25648 [==============================] - 1s 42us/step\n",
      "\n",
      " Accuracy: 0.8541\n"
     ]
    }
   ],
   "source": [
    "save_file='train_keras_model.h5'\n",
    "model.save('./output/'+save_file)\n",
    "\n",
    "print(\"\\n Accuracy: %.4f\" % (model.evaluate(train_data, train_label)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
